<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title></title>
  <generator uri="https://github.com/jekyll/jekyll">Jekyll v3.0.3</generator>
    <icon>/apple-touch-icon-precomposed.png</icon>
  <subtitle></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="/" rel="alternate" type="text/html"/>
  <updated>2016-03-29T10:36:37-04:00</updated>
  <id>/</id>
  <author>
    <name></name>
    <uri>/</uri>
    
  </author>

  
  <entry>
    <title>Tracking Changes to Harvests in Social Feed Manager</title>
    <link href="/posts/2016-03-14-tracking-changes"/>
    <updated>2016-03-14T00:00:00-04:00</updated>
    <id>/posts/tracking-changes</id>
    <author>
      <name></name>
      <uri>/</uri>
      
    </author>
    <content type="html">
      
      &lt;p&gt;In her blog post, “Social Media for Good: the Series, Episode 2”, DPC’s Sara Day Thomson explains:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;New work also reveals the heightened importance of archived social media datasets that make it possible for researchers to re-use data. 
In order for this data to be useful, it must be curated and preserved with sufficient metadata to explain the conditions of its original 
capture and any subsequent actions taken to refine the data. For instance, a researcher may remove a particular hashtag or account as a 
study progresses, changing the resulting dataset. Archivists face a new mandate to develop tools and practices that support these conditions for re-use and reproducibility.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The Social Feed Manager team has heard this loud and clear!  The need to keep track of changes to collection criteria (seeds, harvesting options, credentials, etc.) is reflected in our user stories for the new Social Feed Manager and initial support should be included in our next release (version 0.5.0).  You can follow progress by watching the ticket.  (Keep in mind that we are still pre-version 1.0, so SFM is in active development.)&lt;/p&gt;

&lt;p&gt;We haven’t work on the UI yet, but this should give you an idea of how this feature works.  First I created a new seed set.  (This is an action that might be performed by a researcher or an archivist.)  In SFM, a seed set is a list of seeds for a harvest, where a seed might be a Twitter handle or a Flickr user.  Since the list is in reverse chronological order, the entry for creating the seed set is second.  Second, I changed the schedule of the harvest.  This is the first entry below.&lt;/p&gt;

&lt;p&gt;Seed set changes&lt;/p&gt;

&lt;p&gt;Notice that whenever a change is made, the following is recorded:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Each field and value that is changed. In this example, the schedule was changed.&lt;/li&gt;
  &lt;li&gt;Who made this change.  In this example, “justin” made the change.&lt;/li&gt;
  &lt;li&gt;When the change was made.&lt;/li&gt;
  &lt;li&gt;An optional note describing the reason for the change.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Again, the UI work is still to be done, but you can imagine an (understandable) version of these changes appearing when a user is reviewing a seed set.&lt;/p&gt;

&lt;p&gt;Note that this change history is also tied into how we keep track of harvests – SFM records the exact state of the collection criteria used to perform the harvest.&lt;/p&gt;

&lt;p&gt;For those wondering, this is implemented with django-simple-history.&lt;/p&gt;

&lt;p&gt;If you have thoughts on this feature, comments are welcome.  In particular, we’re interested in ideas about how to make this information available and useful to researchers, especially in dataset exports.  I can be reached @justin_littman or the whole team at sfm-dev.&lt;/p&gt;

&lt;p&gt;(This post originally appeared on the &lt;a href=&quot;https://library.gwu.edu/scholarly-technology-group/posts/tracking-changes-harvests-social-feed-manager&quot;&gt;Scholarly Technology Group’s blog&lt;/a&gt; on the GW Libraries website.)&lt;/p&gt;

    </content>
  </entry>
  
  <entry>
    <title>An Experiment with Social Feed Manager and the ELK Stack</title>
    <link href="/posts/elk-experiment/"/>
    <updated>2016-01-13T00:00:00-05:00</updated>
    <id>/posts/elk-experiment</id>
    <author>
      <name></name>
      <uri>/</uri>
      
    </author>
    <content type="html">
      
      &lt;p&gt;The latest in our social media harvesting experiments for the &lt;a href=&quot;https://github.com/gwu-libraries/sfm-ui&quot;&gt;Social Feed Manager&lt;/a&gt; project involves analysis, discovery, and visualization of social media content. An analytics service may help satisfy two needs:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;For the collection creator, being able to evaluate the content that is being collected so as to adjust the collection criteria. For example, for Twitter a collection creator may discover additional hashtags to collect. Since a collection creator may be collecting a rapidly evolving event, this requires near real-time analysis.&lt;/li&gt;
  &lt;li&gt;For the researcher, being able to analyze the content. Though many researchers will need to export the social media content for use with other tools, having available some sort of an analytics service may meet the needs of some researchers and may lower the barrier to performing social media research.
We also wanted to test the extensibility of the SFM architecture to make sure that additional services can be readily added.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The ELK (Elasticsearch, Logstash, Kibana) stack was selected for this experiment. It was selected primarily on the intuition that it was a good fit, rather than an analysis of its features or a comparison against other options. For those not familiar with this stack, Kibana is the discovery and visualization interface, Elasticsearch is the data store, and Logstash loads Elasticsearch with data. We’ll refer to our own implementation as SFM-ELK.&lt;/p&gt;

&lt;p&gt;In SFM infrastructure, harvesters, such as the Twitter harvester, invoke the APIs of social media platforms and record the results in WARC files. Harvesters publish warc_created messages to a message queue whenever a WARC file is created. This provides the critical hook for SFM-ELK to perform loading – a message consumer application listens for warc_created messages. When it receives a warc_created message, it:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Invokes the appropriate WARC iterator (e.g., TwitterRestWarcIter) to read the WARC file and output the social media records as line-oriented JSON.&lt;/li&gt;
  &lt;li&gt;Pipes this to jq, which filters the JSON. Most types of social media records contain extraneous metadata which do not need to be indexed in Elasticsearch. Logstash supports various mechanisms for filtering and transforming loaded data, but jq proved better for JSON data.&lt;/li&gt;
  &lt;li&gt;Pipes this into Logstash, which loads it into Elasticsearch.
Once properly loaded into Elasticsearch, the data is available for discovery and visualization using Kibana. Note that additional data is loaded as new WARC files are created.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For the purposes of this experiment, data harvested from Twitter’s search API using the search terms “gwu” and “gelman” was used.&lt;/p&gt;

&lt;p&gt;While understanding the full power and flexibility of Kibana involves a significant learning curve, some of the functionality is readily usable. For example, to discover the tweets mentioning GWU’s President Knapp, enter “knapp” in the search box on the Discover screen:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://library.gwu.edu/sites/default/files/news-events/Screen%20Shot%202016-01-13%20at%209.52.03%20AM.png&quot; alt=&quot;Search on &amp;quot;knapp&amp;quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;or to find tweets posted by @gelmanlibrary:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://library.gwu.edu/sites/default/files/news-events/Screen%20Shot%202016-01-13%20at%209.54.47%20AM.png&quot; alt=&quot;Search on tweets by @gelmanlibrary&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kibana allows you to easily adjust the timeframe of any discovery or visualization:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://library.gwu.edu/sites/default/files/news-events/Screen%20Shot%202016-01-13%20at%209.56.58%20AM.png&quot; alt=&quot;Change search timeframe&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To demonstrate the sort of visualizations that might be useful for a collection creator or researcher, we created a Twitter dashboard:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://library.gwu.edu/sites/default/files/news-events/Screen%20Shot%202016-01-13%20at%209.59.44%20AM.png&quot; alt=&quot;Twitter dashboard&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here’s each of those visualizations in a more readable size:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://library.gwu.edu/scholarly-technology-group/posts/experiment-social-feed-manager-and-elk-stack&quot; alt=&quot;Tweet rate visualization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://library.gwu.edu/sites/default/files/news-events/Screen%20Shot%202016-01-13%20at%2010.01.38%20AM.png&quot; alt=&quot;Top URLs visualization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://library.gwu.edu/sites/default/files/news-events/Screen%20Shot%202016-01-13%20at%2010.01.51%20AM.png&quot; alt=&quot;Top hashtags visualization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://library.gwu.edu/sites/default/files/news-events/Screen%20Shot%202016-01-13%20at%2010.02.08%20AM.png&quot; alt=&quot;Top user mentions visualization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://library.gwu.edu/sites/default/files/news-events/Screen%20Shot%202016-01-13%20at%2010.02.22%20AM.png&quot; alt=&quot;Top tweeters visualization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note that the dashboard is periodically refreshed as new data is added.&lt;/p&gt;

&lt;p&gt;As should be evident, this experiment barely scratches the surface of the capabilities of the ELK stack, or more generally, the potential of adding an analytics service to Social Feed Manager.  The code for SFM-ELK is available at https://github.com/gwu-libraries/sfm-elk. Instructions are provided to bring up a Docker environment so that you can give it a try yourself. Keep in mind that this is only a proof-of-concept and it is not currently in scope of SFM development.&lt;/p&gt;

&lt;p&gt;If any of this is of interest to you or your organization, collaborators are welcome.&lt;/p&gt;

&lt;p&gt;P.S.  It was &lt;a href=&quot;https://www.arhu.umd.edu/news/documenting-now-archiving-social-media-generations-come&quot;&gt;just announced&lt;/a&gt; that Washington University in St. Louis, the Maryland Institute for Technology in the Humanities (MITH) at the University of Maryland, and the University of California, Riverside were awarded a Mellon grant for a project titled “Documenting the Now: Supporting Scholarly Use and Preservation of Social Media Content.” Since there’s a clear need to support researchers’ and archivists’ needs for good analytical tools, we look forward to their work. Follow the project at &lt;a href=&quot;https://twitter.com/documentnow&quot;&gt;@documentnow&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;(This post was originally posted on the &lt;a href=&quot;https://library.gwu.edu/scholarly-technology-group/posts/experiment-social-feed-manager-and-elk-stack&quot;&gt;Scholarly Technology Group’s blog&lt;/a&gt; on the GW Libraries website.)&lt;/p&gt;

    </content>
  </entry>
  
  <entry>
    <title>Harvesting the Twitter Streaming API to WARC files</title>
    <link href="/posts/2015-12-15-harvesting-twitter-streams"/>
    <updated>2015-12-15T00:00:00-05:00</updated>
    <id>/posts/harvesting-twitter-streams</id>
    <author>
      <name></name>
      <uri>/</uri>
      
    </author>
    <content type="html">
      
      &lt;p&gt;The Twitter Streaming API is very powerful, allowing harvesting tweets not readily available from the other APIs. However, recall from our previous post that the Twitter Streaming API does not behave like REST APIs that are typical of social media platforms – see Twitter’s description of the differences. A single HTTP response is potentially huge and may be collected over the course of hours, days, or weeks. This is a poor fit for both the normal web harvesting model in which a single HTTP response is recorded as a single WARC response record in a single WARC file, and for most web archiving tools, which store HTTP responses in-memory and don’t write them to the WARC file until the response is completed.&lt;/p&gt;

&lt;p&gt;This post describes an approach we’ve developed for harvesting the Twitter Streaming API and recording in WARC files. We will also show how the tweets can be extracted from the WARC files for use by a researcher.&lt;/p&gt;

&lt;p&gt;The Twitter Streaming API is not the only form of streaming content on the Web and the authors of WARC Specification had the forethought to support record segmentation. In record segmentation, a single HTTP response is split into multiple WARC records, potentially in multiple WARC files. The first record is a WARC response record; subsequent records are WARC continuation records. The header of the final continuation record also contains the total number of bytes of the entire HTTP response.&lt;/p&gt;

&lt;p&gt;While WARC record segmentation is theoretically a good solution for the Twitter Streaming API, record segmentation is not widely supported in most web archiving tools. Our first step was to modify Internet Archive’s warcprox to support record segmentation. (Our pull request is #15. The crux of the change is between lines 210 and 245 in warcprox.py.) Recall from the earlier post that warcprox is an HTTP proxy that records the HTTP transaction in a WARC.&lt;/p&gt;

&lt;p&gt;The following shows snippets from a WARC file created by the modified warcprox from the Twitter filter API retrieved by twarc tracking “obama”. It consists of a WARC response record, a request record, a continuation record, and a final continuation record.&lt;/p&gt;

&lt;p&gt;WARC/1.0
WARC-Type: response
WARC-Record-ID: &lt;urn:uuid:9aff4bf7-d64a-411c-9ef8-cd82778e036e&gt;
WARC-Date: 2015-12-02T16:59:07Z
WARC-Target-URI: https://stream.twitter.com/1.1/statuses/filter.json
WARC-IP-Address: 199.16.156.20
Content-Type: application/http;msgtype=response
WARC-Segment-Number: 1
Content-Length: 1149
WARC-Block-Digest: sha1:7c8de1bd439cf62c67f9f4b0c48e6f3ae39eb4ef
WARC-Payload-Digest: sha1:cc1b7bf9a2945ddf8ae7c35d5f05513d0d8b691b&lt;/urn:uuid:9aff4bf7-d64a-411c-9ef8-cd82778e036e&gt;&lt;/p&gt;

&lt;p&gt;HTTP/1.1 200 OK
connection: close
content-Encoding: gzip
content-type: application/json
date: Wed, 02 Dec 2015 16:59:07 GMT
server: tsa
transfer-encoding: chunked
x-connection-hash: 8439cf557d0f807635797377d9e7d0b6&lt;/p&gt;

&lt;p&gt;a
?
1f1
tSۊ?0??A/}?%??ر??^???¶??P?q#”KF??n??w?ٔ%?O3?͜?y&lt;code class=&quot;highlighter-rouge&quot;&gt;?GQ    Y?~?????!+?U??
^r? ?ي?bZ???r^WeU?_?:[?ѓ??$?&quot;?I?7????1&lt;/code&gt;?ہ?;?oH?}?a?v?.?ε
                                                        }???F???t??|???N??????m?i?t??9?
??1???B?c?A?&amp;lt;?;a?/???&amp;amp;?d?dkziR?Vxͽ????q                                                ??8?څ??;?Z
“?c’c?$g?????
????
    4???ʁ|???5?Y-k???z???9FM?&amp;lt;v{?v픗2K&amp;gt;_?2!??d????q?v???E?{|??ct???=???=n??_E
IQ?’?
U?&amp;amp;??]???n?ֽ??”?(:&lt;em&gt;?6,???F??????4:?%??
?=-??x?-ל????EQ????N&amp;gt;?????VOW???c’\???^gk?Z=???lZ???y??
163
?U?n?0???C?^??Æ^
=?T?)?4X_U????7~T?75??~Q?˵Ғ1??????&lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;????c?wfgR?&lt;/code&gt;?g???kp&amp;lt;???r)+.
?4zD?????ie6?/F????˭&lt;/em&gt;???   Xm??rLhEiƈs???B)y???b;a??Am??d׮?&amp;lt;??ԍNȄ?$????T?r?ϝ,ot?m???L???
                        ?j4??.??Q??b???%????7?????????7??XT?2B%?,aQ?4I?p??wn?z
                                                                                ??\??7`
                                                                                       R{Z???8?Ϲ&amp;lt;?$?t??)u?^?5?u?{}?K??yOo?]?(??.f??|??m????
229
[o?0???’q???6??-J?.?z@k’??IL@??&lt;/p&gt;

&lt;p&gt;WARC/1.0
WARC-Type: request
WARC-Record-ID: &lt;urn:uuid:3a6ce873-13a9-401a-bfd9-3ddc321aab96&gt;
WARC-Date: 2015-12-02T16:59:07Z
WARC-Target-URI: https://stream.twitter.com/1.1/statuses/filter.json
WARC-Concurrent-To: &lt;urn:uuid:9aff4bf7-d64a-411c-9ef8-cd82778e036e&gt;
WARC-Block-Digest: sha1:fa301cb54fd6c38adac4a43bacf36d38198ec8e0
Content-Type: application/http;msgtype=request
Content-Length: 566&lt;/urn:uuid:9aff4bf7-d64a-411c-9ef8-cd82778e036e&gt;&lt;/urn:uuid:3a6ce873-13a9-401a-bfd9-3ddc321aab96&gt;&lt;/p&gt;

&lt;p&gt;POST /1.1/statuses/filter.json HTTP/1.1
content-length: 30
accept-encoding: deflate, gzip
host: stream.twitter.com
accept: &lt;em&gt;/&lt;/em&gt;
user-agent: python-requests/2.8.1
content-type: application/x-www-form-urlencoded
authorization: OAuth oauth_nonce=”149931870481283598461449075546”, oauth_timestamp=”1449075546”, oauth_version=”1.0”, oauth_signature_method=”HMAC-SHA1”, oauth_consumer_key=”EHdoTe7ksBgflP5nUalEfhaeo”, oauth_token=”481186914-c2yZjbk1np0Z5MWEFYYQKSQNFBXd8T9r4k90YkJl”, oauth_signature=”m0hHjrPnU7aTtOhjmk8om3Vv7Ok%3D”&lt;/p&gt;

&lt;p&gt;track=obama&amp;amp;stall_warning=True&lt;/p&gt;

&lt;p&gt;WARC/1.0
WARC-Type: continuation
WARC-Record-ID: &lt;urn:uuid:c18791da-24e0-42a7-91df-82dfdae6697e&gt;
WARC-Date: 2015-12-02T16:59:07Z
WARC-Target-URI: https://stream.twitter.com/1.1/statuses/filter.json
WARC-IP-Address: 199.16.156.20
Content-Type: application/http;msgtype=response
WARC-Segment-Number: 2
WARC-Segment-Origin-ID: &lt;urn:uuid:9aff4bf7-d64a-411c-9ef8-cd82778e036e&gt;
Content-Length: 1220
WARC-Block-Digest: sha1:82794503724ba3bb06fee69302614a3f5ef00c39&lt;/urn:uuid:9aff4bf7-d64a-411c-9ef8-cd82778e036e&gt;&lt;/urn:uuid:c18791da-24e0-42a7-91df-82dfdae6697e&gt;&lt;/p&gt;

&lt;p&gt;?????a??N?*M???_l???y”uU]IZ&lt;code class=&quot;highlighter-rouge&quot;&gt;RU1?/?n?V?&lt;/code&gt;???&amp;amp;H??h?U??x??Ea j???mٌSjfsr¨??ê˽RN?&amp;amp;F’?&lt;?h^H~ ?è?ـ
                                                                                            ??m?@?&#39;?]???:?sT?T?/S??W??t??]M???_??.???o?ҷa??Sn1???/?;Z;?+?PF??
                                       $L?HnD?????x?t?|ľ?    ?    -G^?|?    &quot;?????gr?? ? )?e[????{]vW???j???-??*T&amp;?{)2\?9^?`\?_??&gt;?.-????ҚO??{v?+?W??4??ps %c?8?’?&lt;code class=&quot;highlighter-rouge&quot;&gt;?nU???a??%?q?/q?о?X???&amp;amp;???G}71G?&amp;amp;V?
                                                                                  ?w?ȱZn?ӯ?&amp;amp;?*C??&amp;amp;s?R???rRa???? ?j??es??q?@?s??\/7?w??v?????+???2(????????mNS?
?iZ?????p}?8?.?????????;??
16c
̘AO?0ǿ
     g?F˸??&amp;amp;?!?u???2D????&amp;amp;U?Ń&#39;J?ڒ??????????K5??pBm?T??=)?0?
                                                           8Ę?????Ԉ,?
                                                                     O??&amp;gt;u?~???3?A???Ώho??[?rYV&#39;??jW??J?e?IV?r?d?*L6    ;???????i/
R-       ??
  ??Y?Cĭ??
          ??2]vj ??7??C5B??????!?;????m(j???^?d/??jK??m?d?K ,???|P˂?ۥF2??5*%&lt;/code&gt;Lﲞ?x\g????’qs?F?
                                                                                               ?O?
                                                                                                  ?=Ԥz&lt;code class=&quot;highlighter-rouge&quot;&gt;??k+?l?gS????
                                                                                                                    qU?g#?S????3??SӕS???&lt;/code&gt;2=HM?-?
??Ys?5S?O???
68
??    U??X?&lt;???̀4?B???Q&#39;Ԇ7(?!?S?፮?&gt;F??^??????Rm,?A????r?&amp;lt;(e??:?28;?f????
1a1
??OO?@??&amp;amp;~    ?”?”??D?5?Lj6P?,?@K??    [
?F?`????~? ???&amp;lt;?T5? ???%’ap,$?FCZ????vP???D?N?8p?-/???l[??y???#?{]??(?J????’E?&amp;amp;΃???զj???X??7?&amp;lt;Ɩg?ՅU?Bh%
                                                                                                           m??u?h????????s?N??u????u??0֜d&lt;/p&gt;

&lt;p&gt;WARC/1.0
WARC-Type: continuation
WARC-Record-ID: &lt;urn:uuid:d7bfe010-7831-45a8-8361-715692ea014b&gt;
WARC-Date: 2015-12-02T16:59:09Z
WARC-Target-URI: https://stream.twitter.com/1.1/statuses/filter.json
WARC-IP-Address: 199.16.156.20
Content-Type: application/http;msgtype=response
WARC-Segment-Number: 3
WARC-Segment-Origin-ID: &lt;urn:uuid:9aff4bf7-d64a-411c-9ef8-cd82778e036e&gt;
WARC-Segment-Total-Length: 924
WARC-Truncated: unspecified
Content-Length: 307
WARC-Block-Digest: sha1:57b73cdaab8025cc04a83f3ae6eff2dd6e2bfa15&lt;/urn:uuid:9aff4bf7-d64a-411c-9ef8-cd82778e036e&gt;&lt;/urn:uuid:d7bfe010-7831-45a8-8361-715692ea014b&gt;&lt;/p&gt;

&lt;p&gt;?^,~0??Cc?43??n????8???????A^]d???ן&amp;amp;??qSN?FZ
??m?$p? ?&amp;amp;?A?p$?$?S??d,^zk?#?Y    ?q?g~????R????P?\???~??w??T?&amp;amp;`
                                                              ????L?r????i????Th2?2B??$?C??:????T?????
20e
tRMk?@?+??C]YV??T
NqZHS?K/??F???Y?QE?|GVjB?u?a?y??͋(,J??Vz???X?&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;??̲i??)&lt;/td&gt;
      &lt;td&gt;???$?L?H?Rd?y???”&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;As should be obvious, this data is not readily usable by most researchers. In particular, there are four barriers to use:&lt;/p&gt;

&lt;p&gt;It is in a WARC file.
The HTTP response is segmented into multiple WARC records.
The HTTP response has gzip content encoding.
The HTTP response has chunked transfer encoding.
In order to be confident in this approach, we feel it is prudent to make sure that we can access the tweets given these various barriers and the lack of support for record segmentation in web archiving tools. To this end, we developed TwitterStreamWarcIter and the parent class BaseWarcIter.  TwitterStreamWarcIter outputs the tweets from a WARC file, one per line. This is the same output as twarc or cat-ing a line-oriented json file and can be piped to other tools such as jq:&lt;/p&gt;

&lt;p&gt;$ python twitter_stream_warc_iter.py test_1-20151202200525007-00000-30033-GLSS-F0G5RP-8000.warc.gz&lt;/p&gt;

&lt;p&gt;{“contributors”: null, “truncated”: false, “text”: “RT @Litorodbujan: Obama quiere visitar Espa\u00f1a!\nAhora s\u00ed somo
s un pa\u00eds serio; con Rajoy no se repetir\u00e1 esto.   #RajoyconPiqueras https://t.c\u2026”, “is_quote_status”: false,
 “in_reply_to_status_id”: null, “id”: 672144412936445952, “favorite_count”: 0, “source”: “&amp;lt;a href=&quot;https://mobile.twitter.
com&quot; rel=&quot;nofollow&quot;&amp;gt;Mobile Web (M2)&amp;lt;/a&amp;gt;”, “retweeted”: false, “coordinates”: null, “timestamp_ms”: “1449086690540”, “ent
ities”: {“user_mentions”: [{“id”: 320317854, “indices”: [3, 16], “id_str”: “320317854”, “screen_name”: “Litorodbujan”, “nam
….&lt;/p&gt;

&lt;p&gt;or suitable for human-consumption with the –pretty flag:&lt;/p&gt;

&lt;p&gt;$ python twitter_stream_warc_iter.py test_1-20151202200525007-00000-30033-GLSS-F0G5RP-8000.warc.gz –pretty&lt;/p&gt;

&lt;p&gt;{
    “contributors”: null, 
    “truncated”: false, 
    “text”: “RT @Litorodbujan: Obama quiere visitar Espa\u00f1a!\nAhora s\u00ed somos un pa\u00eds serio; con Rajoy no se repetir\u00e1 esto.   #RajoyconPiqueras https://t.c\u2026”, 
    “is_quote_status”: false, 
    “in_reply_to_status_id”: null, 
    “id”: 672144412936445952, 
    “favorite_count”: 0, 
    “source”: “&amp;lt;a href=&quot;https://mobile.twitter.com&quot; rel=&quot;nofollow&quot;&amp;gt;Mobile Web (M2)&amp;lt;/a&amp;gt;”, 
    “retweeted”: false, 
    “coordinates”: null, 
    “timestamp_ms”: “1449086690540”, 
    “entities”: {
….&lt;/p&gt;

&lt;p&gt;This approach addresses the WARC barrier by using Internet Archive’s WARC library to read the WARC file. The IA WARC library is extended to handle record segmentation by stitching the payload back together. (See CompositeFilePart. It still doesn’t handle continuations that are in other WARC files, but solving that problem is just software development.) And lastly, the content encoding and transfer encoding barriers are remedied by loading the payload into a urllib3 HTTPResponse which handles the decoding of the content encoding and transfer encoding, as well as providing a familiar, pythonic interface to the response.&lt;/p&gt;

&lt;p&gt;As we have explored the similarity between web harvesting and social media harvesting, the Twitter Streaming API represents the point of greatest friction. However, the above represents a reasonable first approach to addressing the unique features of the Twitter Streaming API.&lt;/p&gt;

&lt;p&gt;(This post originally appeared on the &lt;a href=&quot;https://library.gwu.edu/scholarly-technology-group/posts/harvesting-twitter-streaming-api-warc-files&quot;&gt;Scholarly Technology Group’s blog&lt;/a&gt;)
n the GW Libraries website.)&lt;/p&gt;

    </content>
  </entry>
  
  
</feed>